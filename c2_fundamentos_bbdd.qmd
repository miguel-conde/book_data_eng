# Fundamentos de Bases de Datos para Data Scientists

## Introducci√≥n a Bases de Datos Relacionales vs NoSQL

Las bases de datos son la **columna vertebral** de cualquier sistema de datos. En este cap√≠tulo, aprenderemos los conceptos clave de bases de datos relacionales, SQL y t√©cnicas de optimizaci√≥n. Adem√°s, exploraremos **formatos eficientes de almacenamiento**, introduciremos **Data Lakes con MinIO** y veremos **una comparaci√≥n te√≥rica entre Data Warehouses y PostgreSQL**.

Las bases de datos se dividen en dos grandes categor√≠as:

**Bases de datos relacionales (SQL)**

-   Almacenan datos en **tablas con filas y columnas**.

-   Soportan **lenguaje SQL** para realizar consultas estructuradas.

-   **Ejemplos:** PostgreSQL, MySQL, MariaDB, SQL Server.

-   **Casos de uso:**

    -   Sistemas transaccionales (ventas, facturaci√≥n, clientes).

    -   An√°lisis de datos estructurados.

**Bases de datos NoSQL**

-   No siguen un esquema r√≠gido de tablas y pueden almacenar datos en varios formatos:

    -   **Documentos:** MongoDB (JSON-like).

    -   **Claves-valor:** Redis.

    -   **Columnas:** Apache Cassandra.

    -   **Grafos:** Neo4j.

-   **Casos de uso:**

    -   Aplicaciones en tiempo real con alta escalabilidad.

    -   Almacenamiento flexible de datos no estructurados.

üí° **Ejemplo:**\
Un e-commerce puede usar **PostgreSQL** para almacenar pedidos y clientes (estructurado) y **MongoDB** para guardar datos de navegaci√≥n del usuario (no estructurado).

## Fundamentos de SQL (PostgreSQL)

PostgreSQL es un **motor de base de datos relacional open-source** con caracter√≠sticas avanzadas, como indexaci√≥n eficiente y soporte para JSON.

**Conceptos clave de SQL:**

-   **SELECT:** para consultar datos.

-   **JOINs:** combinaciones de datos de varias tablas.

-   **GROUP BY & HAVING:** agregaciones sobre conjuntos de datos.

-   **√çndices:** optimizaci√≥n de b√∫squeda de datos.

-   **Vistas y Materialized Views:** consultas reutilizables.

üí° **Ejemplo de consulta en PostgreSQL:**

``` sql
SELECT customer_name, SUM(amount) AS total_spent 
FROM orders 
GROUP BY customer_name 
HAVING SUM(amount) > 500;
```

üìå **Explicaci√≥n:** Agrupa los pedidos por cliente y devuelve aquellos con un gasto total superior a 500.

## Dise√±o de Esquemas de Bases de Datos

El dise√±o de esquemas afecta la **eficiencia y escalabilidad** de una base de datos.

**Normalizaci√≥n vs Denormalizaci√≥n**

-   **Normalizaci√≥n:**

    -   Minimiza redundancia y mejora consistencia.

    -   Divide datos en m√∫ltiples tablas con relaciones.

    -   **Ejemplo:** Separar clientes, pedidos y productos en tablas distintas.

-   **Denormalizaci√≥n:**

    -   Reduce la cantidad de `JOINs` en consultas frecuentes.

    -   Aumenta redundancia pero mejora performance en ciertos casos.

üí° **Ejemplo de esquema normalizado:**

``` sql
CREATE TABLE customers (
    id SERIAL PRIMARY KEY,     
    name TEXT,     
    email TEXT UNIQUE 
);  

CREATE TABLE orders (
    id SERIAL PRIMARY KEY, 
    customer_id INT REFERENCES customers(id),
    amount DECIMAL,
    order_date TIMESTAMP 
);
```

üìå **Explicaci√≥n:** En lugar de almacenar informaci√≥n repetida del cliente en cada pedido, creamos una relaci√≥n con `customer_id`.

## Indexaci√≥n y Optimizaci√≥n de Consultas

Las bases de datos pueden volverse **lentas** a medida que crecen. Para evitar esto, se usan **√≠ndices y optimizaci√≥n de consultas**.

**Tipos de √≠ndices en PostgreSQL**

1.  **√çndices B-Tree (Por defecto)** ‚Üí √ötiles para `WHERE` en valores √∫nicos o rango.

2.  **√çndices Hash** ‚Üí Para b√∫squedas exactas.

3.  **√çndices GIN** ‚Üí Para b√∫squedas en JSON o texto completo.

4.  **√çndices BRIN** ‚Üí Optimizaci√≥n en grandes vol√∫menes de datos ordenados.

üí° **Ejemplo de creaci√≥n de √≠ndice:**

``` sql
CREATE INDEX idx_customer_email ON customers(email);`
```

üìå **Explicaci√≥n:** Agrega un √≠ndice sobre el email del cliente para acelerar b√∫squedas.

üîç **Uso de `EXPLAIN ANALYZE` para analizar rendimiento:**

``` sql
EXPLAIN ANALYZE  SELECT * FROM orders WHERE amount > 100;
```

üìå **Explicaci√≥n:** Muestra el plan de ejecuci√≥n de la consulta y su costo en t√©rminos de tiempo y recursos.

## Almacenamiento Eficiente de Datos en Formatos Parquet y Avro

**Por qu√© no siempre usar CSV o JSON**

-   **CSV:** ocupa mucho espacio y es lento para grandes vol√∫menes.

-   **JSON:** flexible pero pesado y dif√≠cil de optimizar.

**Formatos optimizados**

1.  **Parquet:**

    -   Formato columnar (excelente para consultas anal√≠ticas).

    -   Soporta compresi√≥n eficiente.

    -   Se usa en Apache Spark, Snowflake, AWS Athena.

2.  **Avro:**

    -   Formato binario, ideal para transmisi√≥n de datos.

    -   √ötil en Kafka y streaming de eventos.

üí° **Ejemplo de conversi√≥n en Pandas:**

``` python
import pandas as pd  

df = pd.read_csv("data.csv") 
df.to_parquet("data.parquet", engine="pyarrow", compression="snappy")
```

üìå **Explicaci√≥n:** Convierte un CSV en un Parquet optimizado con compresi√≥n **Snappy**.

## Data Lakes en Local con MinIO (Conceptual y Opcional Pr√°ctico)

**¬øQu√© es un Data Lake?**

Un **Data Lake** es un repositorio que almacena datos en **crudo** en m√∫ltiples formatos.

**Diferencias entre Data Warehouse y Data Lake:**

| **Caracter√≠stica** | **Data Warehouse** | **Data Lake** |
|------------------------|------------------------|------------------------|
| Datos | Estructurados | Cualquier formato (JSON, Parquet, im√°genes, logs) |
| Procesamiento | SQL, optimizado para consultas | Flexible, permite ML, Big Data |
| Ejemplo | Snowflake, Redshift | AWS S3, MinIO |

**MinIO: Un Data Lake en Local**

MinIO es un sistema de almacenamiento **compatible con S3**, pero ejecutable en local.

üí° **Ejemplo:**\
Usar MinIO para almacenar archivos Parquet en un Data Lake local y procesarlos con Spark o Dask.

## Introducci√≥n Te√≥rica a Data Warehouses (Snowflake, Redshift, BigQuery) y Comparaci√≥n con PostgreSQL

üìå **Diferencias Clave**

| **Aspecto**   | **PostgreSQL (en local)** | **Snowflake (Cloud DW)**     |
|---------------|---------------------------|------------------------------|
| Escalabilidad | Limitada                  | Alta (autoescalado)          |
| Coste         | Gratis en local           | Pago por uso                 |
| Rendimiento   | Bueno en datos peque√±os   | Optimizado para TBs de datos |
| Formato       | SQL tradicional           | SQL optimizado para DW       |

üí° **Ejemplo pr√°ctico:**\
Si una empresa tiene **10 GB de datos**, PostgreSQL es suficiente. Pero si tiene **10 TB y consultas anal√≠ticas pesadas**, necesita un **Data Warehouse como Snowflake**.

## Conclusi√≥n del Cap√≠tulo

‚úîÔ∏è PostgreSQL es una base de datos **potente y escalable en local**.\
‚úîÔ∏è Formatos como **Parquet y Avro** mejoran el almacenamiento.\
‚úîÔ∏è **Data Lakes (MinIO)** son √∫tiles para almacenar datos en bruto.\
‚úîÔ∏è **Data Warehouses como Snowflake** son ideales para consultas anal√≠ticas en grandes vol√∫menes.

## Anexo 1: Instalaci√≥n de PostgreSQL en Linux y Primeros Pasos

### Instalacion

#### Instalaci√≥n de PostgreSQL en Linux

**En Ubuntu/Debian:**

Ejecuta los siguientes comandos en la terminal:

``` bash
sudo apt update sudo apt install postgresql postgresql-contrib
```

üìå **Explicaci√≥n:**

-   `postgresql`: instala el servidor de base de datos.

-   `postgresql-contrib`: incluye herramientas adicionales.

**En Fedora:**

``` bash
sudo dnf install postgresql-server postgresql-contrib
```

**En Arch Linux:**

``` bash
sudo pacman -S postgresql
```

#### Iniciar el servicio PostgreSQL

Despu√©s de la instalaci√≥n, el servicio se inicia autom√°ticamente. Para verificarlo:

``` bash
sudo systemctl status postgresql
```

Si no est√° en ejecuci√≥n, inicia el servicio manualmente:

``` bash
sudo systemctl start postgresql
```

Para asegurarte de que se inicie en cada reinicio del sistema:

``` bash
sudo systemctl enable postgresql
```

#### Acceder a PostgreSQL y Crear una Base de Datos

**Acceder como usuario `postgres` (administrador por defecto)**

PostgreSQL crea autom√°ticamente un usuario del sistema llamado `postgres`. Para acceder al entorno interactivo de PostgreSQL, usa:

``` bash
sudo -i -u postgres psql
```

Esto abrir√° el shell interactivo `psql`.

**Crear una nueva base de datos**

Dentro de `psql`, ejecuta:

``` sql
CREATE DATABASE mi_base_de_datos;
```

**Crear un nuevo usuario con permisos**

``` sql
CREATE USER mi_usuario WITH PASSWORD 'mi_contrase√±a'; GRANT ALL PRIVILEGES ON DATABASE mi_base_de_datos TO mi_usuario;
```

#### Conectar y Usar PostgreSQL desde la Terminal (`psql`)

**Conectar a una base de datos**

Desde `psql`, usa:

``` bash
\c mi_base_de_datos
```

Si est√°s en la terminal normal de Linux:

``` bash
psql -U mi_usuario -d mi_base_de_datos
```

**Mostrar tablas disponibles**

``` sql
\dt
```

**Ejecutar consultas b√°sicas**

``` sql
SELECT * FROM mi_tabla;
```

**Salir del shell `psql`**

``` bash
\q
```

#### Conectar PostgreSQL desde Python con `psycopg2`

Si quieres interactuar con PostgreSQL desde Python, instala `psycopg2`:

``` bash
pip install psycopg2-binary
```

Ejemplo de conexi√≥n en Python:

``` python
import psycopg2  

conn = psycopg2.connect(     
    dbname="mi_base_de_datos",     
    user="mi_usuario",     
    password="mi_contrase√±a",     
    host="localhost",     
    port="5432" ) 
    
cursor = conn.cursor() 
cursor.execute("SELECT version();") 

print(cursor.fetchone())  

cursor.close() 
conn.close()
```

üìå **Explicaci√≥n:**

-   `connect()` establece la conexi√≥n.

-   `execute()` ejecuta consultas SQL.

#### Conectar PostgreSQL desde un Cliente Gr√°fico

Si prefieres una interfaz gr√°fica, puedes usar **pgAdmin**:

``` bash
sudo apt install pgadmin4
```

Despu√©s, accede desde el navegador en `http://localhost/pgadmin4`.

#### Conclusi√≥n

‚úîÔ∏è Instalaste PostgreSQL en Linux.\
‚úîÔ∏è Creaste una base de datos y un usuario.\
‚úîÔ∏è Aprendiste a conectarte con `psql`, Python (`psycopg2`) y pgAdmin.

### Uso

#### Opciones de Librer√≠as para Interactuar con PostgreSQL

| **Librer√≠a** | **Uso Principal** | **Ventajas** |
|------------------------|------------------------|------------------------|
| `psycopg2` | Interfaz est√°ndar para consultas SQL | R√°pida y estable, buena integraci√≥n con Pandas |
| `sqlalchemy` | ORM y gesti√≥n avanzada de conexiones | Ideal para grandes proyectos con abstracci√≥n de SQL |
| `pg8000` | Cliente nativo en Python (100% Python) | No requiere compilaci√≥n, √∫til en entornos restringidos |
| `asyncpg` | Cliente as√≠ncrono para PostgreSQL | Muy r√°pido, ideal para aplicaciones con alta concurrencia |

**Ejemplo de conexi√≥n con SQLAlchemy** (en lugar de `psycopg2`):

``` python
from sqlalchemy import create_engine 
import pandas as pd  

engine = create_engine("postgresql://mi_usuario:mi_contrase√±a@localhost:5432/mi_base_de_datos")  

df = pd.read_sql("SELECT * FROM mi_tabla", engine) 

print(df.head())
```

üìå **Ventaja:** Integra SQL con Pandas sin escribir consultas expl√≠citas.

#### Trabajar con Tablas en Formato DataFrame

Si tienes una tabla en PostgreSQL y quieres convertirla en un **DataFrame de Pandas**:

**Cargar datos desde PostgreSQL a Pandas**

``` python
import psycopg2 
import pandas as pd  

conn = psycopg2.connect(     
    dbname="mi_base_de_datos",     
    user="mi_usuario",     
    password="mi_contrase√±a",     
    host="localhost",     
    port="5432" )  
    
query = "SELECT * FROM mi_tabla" 
df = pd.read_sql(query, conn) 

conn.close()  

print(df.head())
```

üìå **Ventaja:** F√°cil manipulaci√≥n con Pandas despu√©s de extraer los datos.

#### Manejar Tablas Grandes: Alternativas a Pandas

Cuando las tablas son **grandes (millones de filas)**, Pandas puede volverse lento. Algunas soluciones:

**Usar `chunksize` en Pandas para leer datos en fragmentos**

``` python
for chunk in pd.read_sql(query, conn, chunksize=100000):     
    print(chunk.shape)
```

üìå **Ventaja:** Procesa datos por partes en lugar de cargar todo en memoria.

#### `PyArrow` para Datos en Memoria y PostgreSQL

`PyArrow` es una librer√≠a optimizada para manipular grandes vol√∫menes de datos en memoria.\
Podemos usarla para leer datos m√°s r√°pido desde PostgreSQL:

**Convertir una tabla grande en Apache Arrow:**

``` python
import pyarrow.parquet as pq 
import pyarrow as pa  

table = pa.Table.from_pandas(df) 

pq.write_table(table, "datos.parquet")
```

üìå **Ventaja:**\
‚úÖ **Parquet** es m√°s r√°pido que CSV.\
‚úÖ Permite **lectura parcial de datos** (columnar).\
‚úÖ Se integra con Spark y Dask.

#### `Dask` para DataFrames Grandes en PostgreSQL

Dask permite manejar grandes vol√∫menes de datos como si fueran DataFrames de Pandas, pero sin consumir tanta memoria.

**Ejemplo: Cargar datos desde PostgreSQL a Dask**

``` python
import dask.dataframe as dd  

df = dd.read_sql("SELECT * FROM mi_tabla", engine) 

print(df.head())
```

üìå **Ventaja:**\
‚úÖ Procesa datos en paralelo.\
‚úÖ Maneja datasets m√°s grandes que la memoria RAM.

#### Comparaci√≥n de M√©todos para Tablas Grandes

| **M√©todo** | **Uso Ideal** | **Ventaja Principal** |
|------------------------|------------------------|------------------------|
| Pandas (`pd.read_sql`) | Tablas peque√±as (\<500MB) | F√°cil de usar |
| `chunksize` en Pandas | 500MB - 2GB | Evita cargar todo en memoria |
| `PyArrow` | Tablas grandes en memoria | Optimizado para procesamiento en columna |
| `Dask` | Dataset \> 2GB | Escalabilidad y procesamiento paralelo |

### Conclusi√≥n

‚úîÔ∏è **Para bases de datos peque√±as**, usa `psycopg2` + `Pandas`.\
‚úîÔ∏è **Para datos grandes**, usa `chunksize`, `PyArrow` o `Dask`.\
‚úîÔ∏è **Si necesitas rendimiento extremo**, usa `Dask` o integra con `Spark`.

## Anexo 2 - Acceso remoto a PostgreSQL

### Autenticaci√≥n

PostgreSQL, en la configuraci√≥n por defecto en Ubuntu, utiliza el m√©todo de autenticaci√≥n "peer" para conexiones locales. Con "peer", el sistema compara el nombre del usuario de Linux con el usuario de PostgreSQL. Si intentas conectarte como otro usuario pero tu sesi√≥n de terminal se inici√≥ con otro usuario (por ejemplo, "postgres" o "root"), la autenticaci√≥n falla.

**Cambiar el m√©todo de autenticaci√≥n en pg_hba.conf a "md5"**

Con esto, PostgreSQL usar√° autenticaci√≥n por contrase√±a en lugar de comparar el nombre del usuario del sistema.

1.  **Editar el archivo de configuraci√≥n:**\
    Abre el archivo `/etc/postgresql/16/main/pg_hba.conf` (la ruta puede variar seg√∫n la versi√≥n).

    ``` bash
    sudo nano /etc/postgresql/16/main/pg_hba.conf 
    ```

2.  **Modificar las l√≠neas locales:**\
    Busca las l√≠neas que dicen algo como:

    ``` sql
    local   all             all                                     peer
    ```

    y c√°mbialas por:

    ``` sql
    local   all             all                                     md5
    ```

3.  **Reiniciar el servicio de PostgreSQL:**

    ``` bash
    sudo systemctl restart postgresql
    ```

4.  **Probar la conexi√≥n:**\
    Ahora, al usar `psql -U <usuario> -d mi_base_de_datos -W`, se te pedir√° la contrase√±a y deber√≠as poder conectarte correctamente.

### Conexi√≥n remota mediante pgAdmin

Si al intentar conectarse remotamente con pgAdmin da un error de conexi√≥n, generalmente significa que el servidor de PostgreSQL no est√° escuchando en la direcci√≥n IP que intentas usar o que el puerto 5432 est√° bloqueado.

1.  **Permitir conexiones externas en `postgresql.conf`**

**Editar el archivo `postgresql.conf`**\
Ubicado normalmente en `/etc/postgresql/<versi√≥n>/main/postgresql.conf`. Por ejemplo:

```bash
sudo nano /etc/postgresql/16/main/postgresql.conf
```


**Cambiar `listen_addresses`**\
Busca la l√≠nea que contiene `listen_addresses` y aseg√∫rate de que no est√© comentada (`#`) y que permita escuchar en todas las interfaces (o en la IP espec√≠fica que quieras). Por ejemplo:

```conf
listen_addresses = '*'
```

Si prefieres que solo escuche en la IP local (por seguridad), podr√≠as poner:

```conf
listen_addresses = 'localhost,192.168.1.26'
```

2.  **Configurar el archivo `pg_hba.conf` para aceptar conexiones**

**Editar el archivo `pg_hba.conf`**\
Ubicado normalmente en `/etc/postgresql/<versi√≥n>/main/pg_hba.conf`. Por ejemplo:

```bash
sudo nano /etc/postgresql/16/main/pg_hba.conf
```

**Agregar una l√≠nea para permitir conexiones desde tu red local**\
Por ejemplo, si la red es `192.168.1.0/24`, a√±ade:

```conf
host    all    all    192.168.1.0/24    md5
```

Esto indica que cualquier equipo de la subred `192.168.1.x` puede conectarse a cualquier base de datos con cualquier usuario, usando autenticaci√≥n MD5 (por contrase√±a).

3.  **Reiniciar PostgreSQL**

Despu√©s de hacer estos cambios, reinicia PostgreSQL para que tome la nueva configuraci√≥n:

```bash
sudo systemctl restart postgresql
```

4.  **Verificar firewall (opcional)**

Si tienes un firewall (por ejemplo, UFW en Ubuntu) podr√≠as necesitar abrir el puerto 5432. Por ejemplo:

```bash
sudo ufw allow 5432/tcp
```

(Verifica si realmente lo necesitas y considera la seguridad de tu red.)

5.  **Conectarte desde pgAdmin**

-   **Host**: la IP o el nombre del host donde corre PostgreSQL (por ejemplo, `192.168.1.26` o `<nombre_host`).

-   **Port**: `5432` (por defecto).

-   **Username**: el nombre del usuario que creaste (por ejemplo, `"the-user"` si lo creaste con comillas dobles o sin comillas si usaste un guion bajo).

-   **Password**: la contrase√±a que configuraste.

**Resumen**

1.  Configura `listen_addresses` en `postgresql.conf`.

2.  Ajusta `pg_hba.conf` para permitir conexiones desde tu red local.

3.  Reinicia PostgreSQL.

4.  Revisa el firewall si es necesario.

5.  Intenta conectarte con pgAdmin usando la IP y las credenciales adecuadas.

## Anexo 3 - Instalaci√≥n y Uso de MinIO en Linux

MinIO es una alternativa **en local** a Amazon S3, que permite almacenar archivos en un **Data Lake** y acceder a ellos mediante una API compatible con S3. Es ideal para trabajar con **Parquet, JSON, CSV** y otros formatos en entornos de Big Data.

### Instalaci√≥n

#### üìå M√©todo 1: Instalar y Ejecutar MinIO Manualmente

Ejecuta los siguientes comandos en tu terminal:

``` bash
# Descargar MinIO 
wget https://dl.min.io/server/minio/release/linux-amd64/minio -O minio 
chmod +x minio  # Hacer el archivo ejecutable
```

Ahora inicia MinIO con almacenamiento en la carpeta `~/minio_data`:

``` bash
mkdir -p ~/minio_data ./minio server ~/minio_data --console-address ":9001"
```

Esto inicia el servicio en:

-   **Puerto 9000** (API de MinIO, compatible con S3).

-   **Puerto 9001** (Interfaz web de administraci√≥n).

üí° **Accede a la interfaz web:**\
Abre http://localhost:9001 en tu navegador.\
Usuario y contrase√±a por defecto:

``` vbnet
Access Key: minioadmin 
Secret Key: minioadmin
```

#### üìå M√©todo 2: Instalar MinIO como Servicio en el Sistema

Si quieres que MinIO se ejecute autom√°ticamente al iniciar tu sistema, usa `systemd`:

1Ô∏è‚É£ **Crea un usuario para MinIO (opcional, pero recomendado):**

``` bash
sudo useradd -r minio-user -s /sbin/nologin
```

2Ô∏è‚É£ **Crea la carpeta de datos:**

``` bash
sudo mkdir -p /mnt/minio sudo chown minio-user:minio-user /mnt/minio
```

3Ô∏è‚É£ **Descarga e instala MinIO:**

``` bash
wget https://dl.min.io/server/minio/release/linux-amd64/minio -O /usr/local/bin/minio 
chmod +x /usr/local/bin/minio 
sudo chown minio-user:minio-user /usr/local/bin/minio
```

4Ô∏è‚É£ **Crea un archivo de configuraci√≥n para `systemd`:**

``` bash
sudo nano /etc/systemd/system/minio.service
```

üìå **A√±ade lo siguiente:**

``` ini
[Unit] 
Description=MinIO Storage Service 
After=network.target  

[Service] 
User=minio-user 
Group=minio-user 
ExecStart=/usr/local/bin/minio server /mnt/minio --console-address ":9001" Restart=always  

[Install] 
WantedBy=multi-user.target
```

Guarda y sal de Nano (`CTRL+X`, `Y`, `Enter`).

5Ô∏è‚É£ **Inicia y habilita el servicio:**

``` bash
sudo systemctl daemon-reload sudo systemctl start minio sudo systemctl enable minio
```

üìå **Verifica el estado:**

``` bash
sudo systemctl status minio
```

### Uso

#### Creaci√≥n y Gesti√≥n de Buckets en MinIO

En MinIO, los datos se organizan en **buckets** (equivalentes a carpetas en S3).

##### üìå Crear un Bucket desde la Interfaz Web

1.  Ve a http://localhost:9001.

2.  Inicia sesi√≥n (`minioadmin / minioadmin`).

3.  En "Buckets", haz clic en "Create Bucket".

4.  Introduce un nombre (ejemplo: `mis-datos`) y haz clic en "Create".

##### üìå Crear un Bucket desde la Terminal (`mc`)

`mc` (MinIO Client) es una herramienta de l√≠nea de comandos para gestionar MinIO.

1Ô∏è‚É£ **Descargar e instalar `mc`**

``` bash
wget https://dl.min.io/client/mc/release/linux-amd64/mc -O mc 
chmod +x mc sudo mv mc /usr/local/bin/
```

2Ô∏è‚É£ **Configurar conexi√≥n a MinIO:**

``` bash
mc alias set local http://localhost:9000 minioadmin minioadmin
```

3Ô∏è‚É£ **Crear un Bucket:**

``` bash
mc mb local/mis-datos
```

4Ô∏è‚É£ **Listar Buckets disponibles:**

``` bash
mc ls local
```

#### Subir, Descargar y Listar Archivos en MinIO

##### üìå Subir archivos a MinIO

Subir un archivo CSV al bucket `mis-datos`:

``` bash
mc cp datos.csv local/mis-datos/
```

Subir una carpeta completa:

``` bash
mc cp -r mi_carpeta/ local/mis-datos/
```

##### üìå Listar archivos en un bucket

``` bash
mc ls local/mis-datos/
```

##### üìå Descargar archivos desde MinIO

``` bash
mc cp local/mis-datos/datos.csv .
```

#### Acceder a MinIO desde Python (`boto3`)

Para interactuar con MinIO desde Python, usamos `boto3`, la librer√≠a oficial de Amazon S3.

1Ô∏è‚É£ **Instalar `boto3`:**

``` bash
pip install boto3
```

2Ô∏è‚É£ **Conectar a MinIO en local:**

``` python
import boto3  

# Configuraci√≥n de conexi√≥n 
s3_client = boto3.client(     
    "s3",     
    endpoint_url="http://localhost:9000",     
    aws_access_key_id="minioadmin",     
    aws_secret_access_key="minioadmin" 
    ) 

# Listar Buckets 
buckets = s3_client.list_buckets() 
print("Buckets:", [b["Name"] for b in buckets["Buckets"]])
```

##### üìå Subir archivos desde Python a MinIO

``` python
s3_client.upload_file("datos.csv", "mis-datos", "datos.csv") 
print("Archivo subido con √©xito!")
```

##### üìå Descargar archivos desde MinIO a Python

``` python
s3_client.download_file("mis-datos", "datos.csv", "datos_descargados.csv") 
print("Archivo descargado con √©xito!")
```

#### Trabajar con Archivos Parquet en MinIO

Podemos almacenar y leer archivos Parquet directamente desde MinIO.

##### üìå Guardar DataFrame en MinIO como Parquet

``` python
import pandas as pd 
import pyarrow.parquet as pq 
import pyarrow as pa  

df = pd.DataFrame({"col1": [1, 2, 3], "col2": ["A", "B", "C"]})  

# Guardar como Parquet 
table = pa.Table.from_pandas(df) 
pq.write_table(table, "datos.parquet")  

# Subir a MinIO 
s3_client.upload_file("datos.parquet", "mis-datos", "datos.parquet") 

print("Parquet subido!")
```

##### üìå Leer un Parquet desde MinIO

``` python
import s3fs  

# Conectar MinIO con s3fs 

fs = s3fs.S3FileSystem(client_kwargs={"endpoint_url": "http://localhost:9000"})  

# Leer el archivo directamente 
df = pd.read_parquet("s3://mis-datos/datos.parquet", storage_options={"key": "minioadmin", "secret": "minioadmin"}) 

print(df)
```

### Conclusi√≥n

‚úîÔ∏è Instalaste MinIO en Linux y lo configuraste.\
‚úîÔ∏è Creaste y gestionaste buckets desde la terminal y la web.\
‚úîÔ∏è Interactuaste con MinIO desde Python usando `boto3`.\
‚úîÔ∏è Trabajaste con archivos Parquet y Pandas sobre MinIO.

üìå **Siguientes pasos:**\
üîπ ¬øQuieres integrarlo con Spark o Dask?\
üîπ ¬øNecesitas autenticaci√≥n avanzada con IAM en MinIO?